{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0b0bc-e2b9-442d-a448-f216aef44ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?\n",
    "Overfitting occurs when a model is too complex, and it fits the training data too closely.\n",
    "Regularization\n",
    "Early stopping\n",
    "Underfitting occurs when a model is too simple, and it fails to capture the underlying patterns in the data. \n",
    "Increasing model complexity\n",
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a0ad3-2f7e-4033-9e10-fe2556aef4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief.\n",
    "Regularization: Regularization adds a penalty term to the loss function, which discourages the model from \n",
    "learning complex patterns that may be noise. Regularization techniques like L1, L2, and Dropout are commonly\n",
    "used to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ddb7de-a589-4bdd-a8cf-90eb90d9f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "Underfitting occurs when a model is too simple and unable to capture the underlying patterns in the data\n",
    "Insufficient training data\n",
    "Poor feature selection\n",
    "Model is too simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf2bae-c6ef-47a5-8c4c-323436492d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?\n",
    "The bias-variance tradeoff is a fundamental concept in machine learning that refers to the tradeoff between a models\n",
    "ability to fit the training data (bias) and its ability to generalize to new, unseen data (variance).\n",
    "Bias: Bias refers to the error that is introduced by approximating a real-world problem with a simpler model\n",
    "Variance: Variance refers to the error that is introduced by the models sensitivity to small fluctuations in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ddb42e-a9e2-4281-a830-8d3601438b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?\n",
    "Training and validation curves\n",
    "Cross-validation\n",
    "Regularization\n",
    "To determine whether a model is overfitting or underfitting, it is important to evaluate its performance on both the training \n",
    "and validation datasets. If the model performs well on the training data but poorly on the validation data,\n",
    "it is an indication of overfitting. If the model performs poorly on both the training and validation data, it may be underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f637d-30da-4e9e-a1a7-e70ed55b5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?\n",
    "some common regularization techniques and how they work.\n",
    "Bias refers to the difference between the true values and the predictions made by the model. \n",
    "It represents the models ability to capture the underlying patterns in the data. \n",
    "A high bias model is one that is too simple and unable to capture the complexity of the data. \n",
    "For example, a linear regression model may have high bias if the data has a nonlinear relationship.\n",
    "\n",
    "Variance, on the other hand, refers to the variability in the models predictions when trained on different subsets of the data.\n",
    "A high variance model is one that is too complex and is overfitting the training data. \n",
    "For example, a decision tree model with deep branches may have high variance if it fits the training data too closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e0145-fb34-4c27-8184-8fc248177d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work.\n",
    "Regularization is a technique in machine learning that is used to prevent overfitting by adding a penalty term to the loss function. \n",
    "L1 regularization: also known as Lasso regularization, adds the sum of the absolute values of the coefficients to the loss function.\n",
    "L2 regularization: also known as Ridge regularization, adds the sum of the squares of the coefficients to the loss function.\n",
    "Early stopping: is a simple technique that stops the training process when the performance on a validation set stops improving."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
